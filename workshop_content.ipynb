{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c7d1901-79b7-489e-9e0f-1c562cca352d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Welcome to USS 2022 Machine Learning Workshop!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8873497-6378-4e53-9219-f55a02758626",
   "metadata": {
    "tags": []
   },
   "source": [
    " We have lots prepared for you, so sit tight and lets get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164cae3-11d3-445f-8946-413b29215867",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10873b1-8fd8-4753-8757-7b15040e78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    plot_confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b77b3-a8e6-4efc-8f17-b36bc96c6be9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First we will read in the data set using Panda's read_csv() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ebc43a0-686b-4b79-822f-b63279fd261c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12740\\3389955857.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/Iris.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/Iris.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edaa501f-3757-4cb6-9cb7-88b838983d52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12740\\3771845804.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f81a762-49fb-412d-a349-ea53ada59564",
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_df = pd.read_csv(\"data/transport.csv\")\n",
    "\n",
    "transport_df = transport_df.drop(columns=[\"date \"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be17d615-b563-4b46-83a1-0bdc14e7f376",
   "metadata": {},
   "source": [
    "Now we split the dataset into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a0e8c4-90fa-43b4-afa9-f09c745b3463",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(transport_df, test_size=0.2)\n",
    "\n",
    "X_train, y_train = (train_df.drop(columns=[\"Mode\"]),\n",
    "                   train_df[\"Mode\"])\n",
    "\n",
    "X_test, y_test = (test_df.drop(columns=[\"Mode\"]),\n",
    "                  test_df[\"Mode\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e778f9-b504-4223-92d1-494713833eb8",
   "metadata": {},
   "source": [
    "Lets look at the dataset information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1dff665-6e04-458e-8279-d2b97f717791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 57 entries, 50 to 35\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Mode          57 non-null     object\n",
      " 1   Route         57 non-null     object\n",
      " 2   week          57 non-null     int64 \n",
      " 3   Ticket Price  57 non-null     int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aba28425-ed73-45bf-9e16-aa246aa0b191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mode</th>\n",
       "      <th>Route</th>\n",
       "      <th>week</th>\n",
       "      <th>Ticket Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Plane</td>\n",
       "      <td>mumbai-chennai</td>\n",
       "      <td>3</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Plane</td>\n",
       "      <td>mumbai-Ahmedabad</td>\n",
       "      <td>2</td>\n",
       "      <td>4262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Train</td>\n",
       "      <td>mumbai-Ahmedabad</td>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Train</td>\n",
       "      <td>mumbai-delhi</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Plane</td>\n",
       "      <td>mumbai-Ahmedabad</td>\n",
       "      <td>3</td>\n",
       "      <td>1868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mode             Route  week  Ticket Price\n",
       "50  Plane    mumbai-chennai     3          1890\n",
       "37  Plane  mumbai-Ahmedabad     2          4262\n",
       "43  Train  mumbai-Ahmedabad     2           320\n",
       "6   Train      mumbai-delhi     1           610\n",
       "38  Plane  mumbai-Ahmedabad     3          1868"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "666dcdc9-50d3-41d8-b19c-91e6148550e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mumbai-chennai', 'mumbai-Ahmedabad', 'mumbai-delhi',\n",
       "       'mumbai-Banglore', 'mumbai-hydrabad', 'mumbai-kollkatta'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Route.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5f9fa-7ca9-46db-9bc0-65674b607b87",
   "metadata": {},
   "source": [
    "We can see that Route is a categorical variable. Therefore we need to transform this into dummy binary variables. \n",
    "\n",
    "number dummy variables = # categories - 1\n",
    "\n",
    "How can we do this in python? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65886c-a02b-4935-9443-f393a6c214db",
   "metadata": {},
   "source": [
    "We can use a column transformer! Lets apply one-hot-encoding method to encode the Route column, and scaling to the numeric columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b594789-9add-4b89-ba86-dc0e4ce66f15",
   "metadata": {},
   "source": [
    "1. Specify the columns we want to apply transformations to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "417aed0d-837c-4940-a93d-bda8dbef9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify numeric feats \n",
    "\n",
    "numeric_feats = [ \n",
    "    \"week\", \n",
    "    \"Ticket Price\",\n",
    "]\n",
    "# specify categorical features\n",
    "\n",
    "cat_feat = [\"Route\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862df594-68d0-4c46-8412-a5868ec75d8f",
   "metadata": {},
   "source": [
    "2. Use Skit-learn's columntransformer to ensure transformations happen to each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43525e3d-5743-425d-9f63-32132384fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    \n",
    "      (\n",
    "        StandardScaler(),\n",
    "        numeric_feats,\n",
    "      ),  \n",
    "    (\n",
    "        OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "        cat_feat,\n",
    "    ),  \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1008e9d6-8892-4811-a754-7a63fe024c6d",
   "metadata": {},
   "source": [
    "Now we are ready to train our model! How do we ensure column transformation are applied without any info from the testing set leaking into the model? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769a7450-6e0d-415c-b74c-44a15161db2e",
   "metadata": {},
   "source": [
    "Use a pipeline! The pipeline can be used with any model. Here we are using logistic regression. After making the pipeline, you can call fit on it to build the model. We'll look at that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00399691-b164-454f-8e26-b033c5e8aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(\n",
    "    ct,\n",
    "    LogisticRegression(max_iter = 10000)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6542bde4-6ce9-47b6-b102-2200722ee515",
   "metadata": {},
   "source": [
    "Lets talk about logistic regression. Our goal here is to determine weather someone took a plane or train. We can use logistic regression for classification problems like this one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2842f2-c4fd-45ea-9cc4-c3331c2086db",
   "metadata": {},
   "source": [
    "Logistic regression uses the training data to learn coefficients, which then can be used to calculate prediction probabilities of the each class using the sigmoid function. This allows us to calculate the predicted probability of someone taking the plane vs train based on their data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc23ebc-ab59-4d74-bdfb-0baeb09659e5",
   "metadata": {},
   "source": [
    "**Pros of logistic regression:**\n",
    "\n",
    "    1. easy to interpret: - predicted coeffecients give us info about feature importance and direction \n",
    "    \n",
    "    2. low variance model - less likely to overfit than other models such as tree based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b87d45-f049-4989-b9ee-e8fca3838005",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hyperparamter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc258cd3-54a5-4188-9ef8-379263099057",
   "metadata": {},
   "source": [
    "hyperparamters are used to tune the model during learning. Logistic Regresion model in skit-learn has a hyperparameter called C which is used to control the fundatamental tradeoff of bias and variance, to reduce the likeliness of the model overfitting or underfitting. Larger values of C increase change of overfitting and small values of C increase chance of underfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95feeb3b-d714-408b-b2c3-448d52473061",
   "metadata": {},
   "source": [
    "lets try optimizing the hyperparamter C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef2dda71-6f2f-4f1d-a1f2-b442a285d945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Train Scores</th>\n",
       "      <th>CV Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.938357</td>\n",
       "      <td>0.898485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.991111</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.316228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.162278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.622777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           C  Train Scores  CV Scores\n",
       "0   0.031623      0.938357   0.898485\n",
       "1   0.100000      0.991111   0.966667\n",
       "2   0.316228      1.000000   0.983333\n",
       "3   1.000000      1.000000   1.000000\n",
       "4   3.162278      1.000000   1.000000\n",
       "5  10.000000      1.000000   1.000000\n",
       "6  31.622777      1.000000   1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores = []\n",
    "cv_scores = []\n",
    "\n",
    "C = 10.0 ** np.arange(-1.5, 2, 0.5)\n",
    "\n",
    "for c in C:\n",
    "    \n",
    "    pipe_lr = make_pipeline(\n",
    "    ct, \n",
    "    LogisticRegression(max_iter=1000, C=c),\n",
    "    )\n",
    "    \n",
    "    results = cross_validate(pipe_lr, X_train, y_train, return_train_score=True)\n",
    "    \n",
    "    train_scores.append(results[\"train_score\"].mean())\n",
    "    cv_scores.append(results[\"test_score\"].mean())\n",
    "    \n",
    "\n",
    "scores = pd.DataFrame({\"C\": C, \"Train Scores\": train_scores, \"CV Scores\": cv_scores })\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70fccec-7dbf-4a57-8556-390144d9c373",
   "metadata": {},
   "source": [
    "Now lets fit the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1a3319d-82d3-4986-b960-5a79ac5f3640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['week', 'Ticket Price']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['Route'])])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.1, max_iter=1000))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    ct, \n",
    "    LogisticRegression(max_iter=1000, C=0.1),\n",
    "    )\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd8975-e355-4613-a052-490f8a2c4153",
   "metadata": {},
   "source": [
    "After fitting the model, we can predict on the testing set, and then print the results in a classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c309b5f4-6ddd-495b-ba94-67800f15f92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Plane       1.00      1.00      1.00         8\n",
      "       Train       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(X_test)\n",
    "\n",
    "res = classification_report(\n",
    "        y_test, predict\n",
    "    )\n",
    "\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be2a3eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# prediction probabilities on test set \n",
    "lr_prob = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "#y_test = y_test.map({'Train': 1, '': 0}).astype(int)\n",
    "\n",
    "# roc_auc score on test set \n",
    "roc_lr = roc_auc_score(y_test, lr_prob)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, lr_prob, pos_label= \"Train\")\n",
    "\n",
    "roc_lr = round(roc_lr, 4)\n",
    "\n",
    "auc_label = \"AUC is \" + str(roc_lr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "plt.fill_between(fpr, tpr, color='blue', alpha=0.2, label=auc_label)\n",
    "\n",
    "plt.legend(loc=\"best\");\n",
    "\n",
    "print(roc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16294ef9-7080-4bfa-b27d-376d1ea392ef",
   "metadata": {},
   "source": [
    "YAY! 100% accuracy!!!! This will never happen in the real world. The reason it happens here is because there is such a big price jump from train tickets to planes that the algorithm picks up on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa2cba8-484c-470b-909a-220da6d6d168",
   "metadata": {},
   "source": [
    "now lets look at an example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dd8cd1e-9943-4100-994d-687da4905fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Route</th>\n",
       "      <th>week</th>\n",
       "      <th>Ticket Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mumbai-Banglore</td>\n",
       "      <td>2</td>\n",
       "      <td>5102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Route  week  Ticket Price\n",
       "13  mumbai-Banglore     2          5102"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = X_test.iloc[[10]]\n",
    "input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd83e58-2259-43bb-8d58-817596140e1a",
   "metadata": {},
   "source": [
    "We can get the predicted probability like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c06bcd2a-952d-48b1-84af-4175096cd5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Plane' 'Train']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.85824077, 0.14175923]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.classes_)\n",
    "model.predict_proba(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2860108b-310d-4b4a-9b8a-714df34af474",
   "metadata": {},
   "source": [
    "The ouput is the probability of each class. The model predicted that the probability of the input being a plane is 96%. We can also look at the hard prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "447a0a76-869e-48f5-b64a-c70fb9d0789f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Plane'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d35677d-9cca-4568-8809-16c6d9039b03",
   "metadata": {},
   "source": [
    "This predicts class = plane if the predicted probability for plane is over 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f75fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d77c68f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12740\\2780118065.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m pipe_tree = make_pipeline(\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mct\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'make_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "pipe_tree = make_pipeline(\n",
    "ct, \n",
    "DecisionTreeClassifier(max_depth = None) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8408300c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['week', 'Ticket Price']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['Route'])])),\n",
       "                ('decisiontreeclassifier', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a79e53",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12740\\3335294862.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m res = classification_report(\n\u001b[0;32m      4\u001b[0m         \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe_tree' is not defined"
     ]
    }
   ],
   "source": [
    "pred = pipe_tree.predict(X_test)\n",
    "\n",
    "res = classification_report(\n",
    "        y_test, predict\n",
    "    )\n",
    "\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629c7f88-14e9-493f-989a-beafac9f50dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d60e17e-bb17-4def-babb-f820fb7dabbf",
   "metadata": {},
   "source": [
    "Random forests is a supervised learning algorithm that is comprised of decision trees. Although it can be used both for classification and regression, today we are mainly focus on how to create a random forest classifier using python. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2b506-2a3a-49c3-8d16-cfdaa16e37dd",
   "metadata": {},
   "source": [
    "### What is the random forest algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1702fd-cabd-4a5f-b5fa-5400083a685d",
   "metadata": {},
   "source": [
    "Random forest is a popular supervised machine learning, based on the concept of ensemble learning (which means that multiple classifiers is used collectively to solve a problem). The random forest algorithm relies on multiple decision trees and then accepts the most-voted results from the predictions of each tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28b4eb5-fe1c-41ca-92bf-5929f9947c05",
   "metadata": {},
   "source": [
    "Random forest classifiers have a plethora of applications in multiple domains. Some examples of Random Forest's applications are: Credit Card Fraud Detection, Diabetes Prediction, Breast Cancer Prediction, and Bitcoin Price Detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2ec64c-a4d2-44df-b7ed-f0caeda01086",
   "metadata": {},
   "source": [
    "### How does the algorithm work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eda321-e6b9-4a6b-aacb-6f6ef95461f6",
   "metadata": {},
   "source": [
    "It works in four steps:\n",
    "\n",
    "1. Select random samples from a given dataset.\n",
    "2. Construct a decision tree for each sample and get a prediction result from each decision tree.\n",
    "3. Perform a vote for each predicted result.\n",
    "4. Select the prediction result with the most votes as the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba758d2-9ebb-4310-8dc6-e29ddd70db0a",
   "metadata": {},
   "source": [
    "In this workshop, you will be building a RF model on the iris flower data set. Iris flower data set is a very famous classification set. It comprises the sepal length, sepal width, petal length, petal width, and type of flowers. You can access the data set by importing the datasets library from scikit-learn, and load the iris dataset with `load_iris()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6a7daf-a3f7-42ba-af01-add4d1c0a9e4",
   "metadata": {},
   "source": [
    "### Let's Dive into Some Python Codes Now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c6266-644d-4d20-85c9-84e4dd0fdc3c",
   "metadata": {},
   "source": [
    "Now we are building a model on the iris flower dataset. Start by importing the datasets library from `sklearn`, and load the iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaefd785-814d-44ba-8301-53f1e53d7e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "#Load dataset\n",
    "iris =  datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b82dcd5-67e4-4766-873f-939e634720ca",
   "metadata": {},
   "source": [
    "Let's print the target and feature variable names just to make sure that we are using the right dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e0917f-471a-4b00-a9d8-95c2dc66df00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris.target_names)\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f57df2-beb1-460d-86c7-7b651678ae75",
   "metadata": {},
   "source": [
    "Now we create a dataframe of this iris dataset. Since the species of iris flower is what we are interested in classifying, we first separate columns accordingly into dependent and independent variables.   \n",
    "Steps as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2a5751-554d-4a6d-bfa1-10041017396d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame({\n",
    "    'sepal_length': iris.data[:,0],\n",
    "    'sepal_width': iris.data[:,1],\n",
    "    'petal_length': iris.data[:,2],\n",
    "    'petal_width': iris.data[:,3],\n",
    "    'species': iris.target\n",
    "})\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c31813b-5afa-44cc-8945-e4b874888cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate cols to dependent and independent variables\n",
    "y = data['species']\n",
    "X = data[['sepal_length','sepal_width','petal_length','petal_width']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aace8380-ae79-40d2-9fcf-ff602ee9940b",
   "metadata": {},
   "source": [
    "We then use the `train_test_split` function to split variables into train and test set (Let's take 75% to training and 25% to testing), and train the model on the train set and perform predictions on the test set. Don't forget to import `RandomForestClassifier` from `sklearn.ensemble`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eeff141-2453-4283-9f52-5d83fe55253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25)\n",
    "    \n",
    "# create the classifier\n",
    "classifier = RandomForestClassifier(n_estimators = 100)\n",
    "classifier.fit(X_train, y_train)\n",
    "# make the prediction using the RF model\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d69e7-c521-40c5-a07b-9e50639eeb1e",
   "metadata": {},
   "source": [
    "We now examine the RF model's accuracy using the actual y (species) value and the predicted values given by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29548437-e06b-45e2-ba51-ec4baf5712f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for RF model is:  0.9474\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"The accuracy for RF model is: \", round(metrics.accuracy_score(y_test, y_pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74913b2a-c29e-4823-9f18-854e9fd58c23",
   "metadata": {},
   "source": [
    "And we say the accuracy is pretty high for such model! To make a prediction on a single item, we can also use the `predict()` function.  \n",
    "For example:  \n",
    "    - sepal length = 3  \n",
    "    - sepal width = 6  \n",
    "    - petal length = 6  \n",
    "    - petal width = 4  \n",
    "Now we can predict which type of the iris flower it is as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecc6e926-ebcc-493a-aa93-f16171772754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict([[3,6,6,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e00eac-b901-431c-acc1-f5482c7eb212",
   "metadata": {},
   "source": [
    "Here, the output is 2, which indicates an iris type of Virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3e69b-fb31-4e31-bebc-1720d4507699",
   "metadata": {},
   "source": [
    "Congratulation! You have made it so far and know what a typical random forest classifier in python looks like. If you are interested in learning more about the random forest algorithm, we encourage you to browse through the internet as there are a lot more interesting readings and tutorials regarding the random forest waiting for you to discover!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
